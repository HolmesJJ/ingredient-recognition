{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6687ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"dataset/test/\"\n",
    "TEST_DIRS = glob.glob(\"dataset/test/*\")\n",
    "\n",
    "MODELS = [\"food-seg-103-xception\", \"food-seg-103-densenet201\", \"food-seg-103-inceptionresnetv2\"]\n",
    "CHECKPOINT_PATHS = [\"checkpoints/\" + MODEL + \".h5\" for MODEL in MODELS]\n",
    "MODEL_PATHS = [\"models/\" + MODEL + \".h5\" for MODEL in MODELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_top5(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ad326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    loaded_models = []\n",
    "    for CHECKPOINT_PATH in CHECKPOINT_PATHS:\n",
    "        loaded_models.append(load_model(CHECKPOINT_PATH, custom_objects={\"acc_top5\": acc_top5}))\n",
    "    print(\"Models Loaded\")\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    target_size=(512, 512),\n",
    "    class_mode=\"categorical\")\n",
    "filenames = test_data.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    test_score = model.evaluate(test_data)\n",
    "    print(\"Test Loss: \", test_score[0])\n",
    "    print(\"Test Accuracy: \", test_score[1])\n",
    "    print(\"Test Accuracy Top 5: \", test_score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(\"=\" * 100)\n",
    "    print(MODELS[i])\n",
    "    evaluate(model)\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    predicted_class_indices = []\n",
    "\n",
    "    with tqdm(total=len(test_data.filepaths)) as pbar:\n",
    "        for i, filepath in enumerate(test_data.filepaths):\n",
    "            pbar.set_description(\"Predicting: %d\" % (1 + i))\n",
    "            pbar.update(1)\n",
    "            test_image = load_img(filepath, target_size=(512, 512))\n",
    "            test_image_array = img_to_array(test_image)\n",
    "            test_image_array = np.expand_dims(test_image_array, axis=0)\n",
    "            test_image_array = test_image_array / 255.\n",
    "            prediction = model.predict(test_image_array, verbose=0)\n",
    "            predicted_label = np.argmax(prediction)\n",
    "            predicted_class_indices.append(predicted_label)\n",
    "    \n",
    "    predicted_class_indices = np.asarray(predicted_class_indices)\n",
    "\n",
    "    predicted_classnames = []\n",
    "    true_classnames = []\n",
    "    for i in range(len(filenames)):\n",
    "        predicted_classnames.append(list(test_data.class_indices.keys())[predicted_class_indices.item(i)])\n",
    "        true_classnames.append(list(test_data.class_indices.keys())[test_data.labels[i]])\n",
    "    return pd.DataFrame({\"Filename\": filenames, \"Prediction\": predicted_classnames, \"True\": true_classnames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models:\n",
    "    results.append(predict(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_results = []\n",
    "for i, result in enumerate(results):\n",
    "    test_accuracy = result.loc[(result[\"Prediction\"] == result[\"True\"])].shape[0] / result.shape[0]\n",
    "    mismatched_result = result.loc[~(result[\"Prediction\"] == result[\"True\"])]\n",
    "    mismatched_results.append(mismatched_result)\n",
    "    print(MODELS[i] + \": \" + \"Test Accuracy: \" + str(test_accuracy) + \", Mismatch: \" + str(len(mismatched_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bede7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "\n",
    "for idx, row in results[0].sample(9).reset_index(drop=True).iterrows():\n",
    "    plt.subplot(3, 3, idx + 1)\n",
    "    img = plt.imread(TEST_PATH + row[\"Filename\"])\n",
    "    plt.title(\"Prediction: \" + row[\"Prediction\"] + \"\\nTrue: \" + row[\"True\"])\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed3ef4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for idx, row in mismatched_results[0].sample(9).reset_index(drop=True).iterrows():\n",
    "    plt.subplot(3, 3, idx + 1)\n",
    "    img = plt.imread(TEST_PATH + row[\"Filename\"])\n",
    "    plt.title(\"Prediction: \" + row[\"Prediction\"] + \"\\nTrue: \" + row[\"True\"])\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b563929",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_result = {}\n",
    "for i, result in enumerate(results):\n",
    "    ensemble_result[i] = result[\"Prediction\"]\n",
    "ensemble_result[\"True\"] = results[0][\"True\"]\n",
    "ensemble_result = pd.DataFrame(ensemble_result)\n",
    "ensemble_result.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_result():\n",
    "    truth = 0\n",
    "    for index, row in ensemble_result.iterrows():\n",
    "        predictions = list(row)[:-1]\n",
    "        prediction = max(set(predictions), key=predictions.count)\n",
    "        label = list(row)[-1:][0]\n",
    "        if prediction == label:\n",
    "            truth += 1\n",
    "    return truth / ensemble_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dce4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble Test Accuracy: \" + str(get_ensemble_result()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
